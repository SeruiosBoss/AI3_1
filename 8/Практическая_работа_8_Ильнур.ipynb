{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeruiosBoss/AI3_1/blob/main/8/Практическая_работа_8_Ильнур.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3DZeo7xi2HL"
      },
      "source": [
        "# Практическая работа 8. Основы обучаемых алгоритмов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ФИО: **Мухамеджанов Ильнур Тимурович**\n",
        "\n",
        "Группа: **ПИН-б-о-22-1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIyzax9q7JF"
      },
      "source": [
        "## Задание, Вариант 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1UMdzQGjFix"
      },
      "source": [
        "Необходимо выполнить `визуализацию данных`,\n",
        "хранящихся в файле с использованием библиотеки `matplotlib`. Необходимо обучить\n",
        "модель `регрессии` и найти `значения параметров`, а также `визуализировать факт`, что\n",
        "ваша модель хорошо `интерпретирует эмпирические данные`. Необходимо провести\n",
        "`эксперименты` со следующими параметрами: `скорость обучения`, `начальные\n",
        "значения параметров`. Определите их `влияние` на процесс обучения алгоритма"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlwZaXQrAfd"
      },
      "source": [
        "## Обозначение функций, `визуальзация данных`, обучение модели `регрессии` и `эксперименты` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzShFx3l0l49",
        "outputId": "8a4fddd3-38f1-41cf-f1d0-0be0bccc594f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка данных из файла\n",
        "file_path = 'pr8_16.txt'\n",
        "data = np.loadtxt(file_path)\n",
        "x = data[:, 0]  # Координаты X\n",
        "y = data[:, 1]  # Координаты Y\n",
        "\n",
        "# Нормализация данных для улучшения сходимости\n",
        "x_norm = (x - np.mean(x)) / np.std(x)\n",
        "y_norm = (y - np.mean(y)) / np.std(y)\n",
        "\n",
        "# Функция для вычисления MSE (среднеквадратичная ошибка)\n",
        "def compute_mse(slope, intercept, x, y):\n",
        "    predictions = slope * x + intercept\n",
        "    return np.mean((predictions - y) ** 2)\n",
        "\n",
        "# Реализация градиентного спуска\n",
        "def gradient_descent(x, y, learning_rate, epochs, initial_slope, initial_intercept):\n",
        "    slope = initial_slope\n",
        "    intercept = initial_intercept\n",
        "    mse_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Предсказания модели\n",
        "        predictions = slope * x + intercept\n",
        "\n",
        "        # Градиенты\n",
        "        slope_gradient = -2 * np.mean((y - predictions) * x)\n",
        "        intercept_gradient = -2 * np.mean(y - predictions)\n",
        "\n",
        "        # Обновление параметров\n",
        "        slope -= learning_rate * slope_gradient\n",
        "        intercept -= learning_rate * intercept_gradient\n",
        "\n",
        "        # Запись ошибки для анализа\n",
        "        mse = compute_mse(slope, intercept, x, y)\n",
        "        mse_history.append(mse)\n",
        "\n",
        "    return slope, intercept, mse_history\n",
        "\n",
        "# Визуализация исходных данных\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(x, y, color='blue', label='Данные')\n",
        "plt.title('Распределение точек')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Обучение модели линейной регрессии\n",
        "learning_rate = 0.1\n",
        "initial_slope = 0.0\n",
        "initial_intercept = 0.0\n",
        "epochs = 100\n",
        "slope, intercept, mse_history = gradient_descent(x_norm, y_norm, learning_rate, epochs, initial_slope, initial_intercept)\n",
        "\n",
        "# Предсказания на основе найденных параметров\n",
        "y_pred = slope * x_norm + intercept\n",
        "\n",
        "# Визуализация модели и данных\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(x, y, color='blue', label='Данные')\n",
        "plt.plot(x, y_pred * np.std(y) + np.mean(y), color='red', label=f'Модель (y = {slope:.2f}x + {intercept:.2f})')\n",
        "plt.title('Линейная регрессия')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Вывод параметров модели\n",
        "print(f'Параметры модели: наклон = {slope:.2f}, пересечение = {intercept:.2f}')\n",
        "\n",
        "# Эксперименты с разными скоростями обучения\n",
        "learning_rates = [0.01, 0.1, 0.5]\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "for lr in learning_rates:\n",
        "    slope, intercept, mse_history = gradient_descent(\n",
        "        x_norm, y_norm, lr, epochs, initial_slope, initial_intercept\n",
        "    )\n",
        "    plt.plot(mse_history, label=f'Learning Rate = {lr}')\n",
        "\n",
        "plt.title('Сходимость MSE при разных скоростях обучения')\n",
        "plt.xlabel('Эпоха')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Эксперименты с разными начальными параметрами\n",
        "initial_params = [(0.0, 0.0), (1.0, -1.0), (-1.0, 1.0)]\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "for initial_slope, initial_intercept in initial_params:\n",
        "    slope, intercept, mse_history = gradient_descent(\n",
        "        x_norm, y_norm, learning_rate, epochs, initial_slope, initial_intercept\n",
        "    )\n",
        "    plt.plot(mse_history, label=f'Init Slope = {initial_slope}, Init Intercept = {initial_intercept}')\n",
        "\n",
        "plt.title('Сходимость MSE при разных начальных параметрах')\n",
        "plt.xlabel('Эпоха')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfm23877A4o2"
      },
      "source": [
        "В данной работе были использованы библиотеки `numpy, matplotlib` и модуль `pyplot` для обучения алгоритма линейной регресии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgydWXtBqRUl"
      },
      "source": [
        "1. **Действительно ли алгоритмы могут обучаться? В чем заключается процесс обучения?**  \n",
        "- Да, алгоритмы могут \"обучаться\", но обучение заключается в нахождении оптимальных параметров модели, которые минимизируют ошибку предсказаний.  \n",
        "- **Процесс обучения:**  \n",
        "  - Сбор данных.  \n",
        "  - Разделение данных на тренировочные и тестовые выборки.  \n",
        "  - Определение модели (например, линейная регрессия).  \n",
        "  - Оптимизация параметров модели (например, с использованием градиентного спуска).  \n",
        "  - Оценка качества модели на тестовых данных.  \n",
        "\n",
        "2. **Что такое модель линейной регрессии?**  \n",
        "- **Линейная регрессия** — это модель машинного обучения, используемая для нахождения линейной зависимости между входными (независимыми) переменными \\(X\\) и целевой (зависимой) переменной \\(Y\\).  \n",
        "- Формула модели:  \n",
        "  \\[\n",
        "  y = w_1x_1 + w_2x_2 + \\ldots + w_nx_n + b\n",
        "  \\]  \n",
        "  где \\(w_i\\) — веса (коэффициенты), \\(b\\) — смещение (bias).  \n",
        "- Используется для задач прогнозирования и анализа зависимости.  \n",
        "\n",
        "3. **Каким образом производится подбор параметров модели в процессе градиентного спуска?**  \n",
        "- **Градиентный спуск** — это итеративный метод оптимизации, используемый для минимизации функции ошибки (например, MSE).  \n",
        "  - На каждом шаге алгоритм вычисляет градиент функции ошибки по параметрам \\(w_i\\).  \n",
        "  - Параметры обновляются в направлении противоположном градиенту:  \n",
        "    \\[\n",
        "    w_i = w_i - \\eta \\cdot \\frac{\\partial L}{\\partial w_i}\n",
        "    \\]  \n",
        "    где \\(\\eta\\) — темп обучения, \\(L\\) — функция ошибки.  \n",
        "  - Цель — минимизировать \\(L\\) за минимальное количество итераций.  \n",
        "\n",
        "4. **Что такое темп обучения? Как влияет данный гиперпараметр на процесс обучения?**  \n",
        "- **Темп обучения (\\(\\eta\\))** — это гиперпараметр, определяющий размер шага при обновлении параметров модели в процессе градиентного спуска.  \n",
        "  - Если \\(\\eta\\) слишком мал:  \n",
        "    - Процесс обучения будет медленным.  \n",
        "    - Модель может застрять в локальном минимуме.  \n",
        "  - Если \\(\\eta\\) слишком велик:  \n",
        "    - Модель может \"перепрыгивать\" через оптимум.  \n",
        "    - Возможна неустойчивость и дивергенция.  \n",
        "\n",
        "5. **Основные типы диаграмм Matplotlib и функции для их построения:**  \n",
        "- **Линейный график (`plot`)**:  \n",
        "  Для отображения зависимостей.  \n",
        "  ```python\n",
        "  plt.plot([1, 2, 3], [4, 5, 6])\n",
        "  plt.show()\n",
        "  ```  \n",
        "\n",
        "- **Гистограмма (`hist`)**:  \n",
        "  Для отображения распределения данных.  \n",
        "  ```python\n",
        "  plt.hist([1, 2, 2, 3, 3, 3, 4], bins=4)\n",
        "  plt.show()\n",
        "  ```\n",
        "\n",
        "- **Диаграмма разброса (`scatter`)**:  \n",
        "  Для отображения точек данных.  \n",
        "  ```python\n",
        "  plt.scatter([1, 2, 3], [4, 5, 6])\n",
        "  plt.show()\n",
        "  ```\n",
        "\n",
        "- **Круговая диаграмма (`pie`)**:  \n",
        "  Для отображения пропорций.  \n",
        "  ```python\n",
        "  plt.pie([15, 30, 45, 10], labels=['A', 'B', 'C', 'D'])\n",
        "  plt.show()\n",
        "  ```\n",
        "\n",
        "- **Столбчатая диаграмма (`bar`)**:  \n",
        "  Для сравнения величин.  \n",
        "  ```python\n",
        "  plt.bar(['A', 'B', 'C'], [10, 20, 15])\n",
        "  plt.show()\n",
        "  ```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP8QFeWhqyUPlS4P3jU6FYS",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
